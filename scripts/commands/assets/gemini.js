const { GoogleGenAI, Modality } = require('@google/genai');
const { AttachmentBuilder, EmbedBuilder, ActionRowBuilder, ButtonBuilder, ButtonStyle, StringSelectMenuBuilder } = require('discord.js');
const axios = require('axios');
const fs = require('fs-extra');
const path = require('path');

const ai = new GoogleGenAI({ apiKey: process.env.GEMINI_API_KEY || '' });

const conversationHistory = new Map();
const MAX_HISTORY = 10;

module.exports = {
    config: {
        name: "gemini",
        aliases: ["gem", "ai", "gpt"],
        version: "2.0",
        author: "Samir",
        countDown: 5,
        role: 0,
        description: {
            en: "Ultimate Gemini AI with text, image, video, audio analysis and generation capabilities",
            ne: "‡§™‡§æ‡§†, ‡§õ‡§µ‡§ø, ‡§≠‡§ø‡§°‡§ø‡§Ø‡•ã, ‡§Ö‡§°‡§ø‡§Ø‡•ã ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§∞ ‡§â‡§§‡•ç‡§™‡§æ‡§¶‡§® ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§≠‡§è‡§ï‡•ã ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä AI"
        },
        category: "ai",
        guide: {
            en: `{prefix}gemini <prompt> - Chat with Gemini AI
{prefix}gemini [image] <question> - Analyze images
{prefix}gemini [video] <question> - Analyze videos  
{prefix}gemini [audio] <question> - Transcribe/analyze audio
{prefix}gemini generate <description> - Generate images
{prefix}gemini clear - Clear conversation history

Features: Conversation memory, multi-modal understanding, image generation, streaming responses`,
            ne: `{prefix}gemini <‡§™‡•ç‡§∞‡§Æ‡•ç‡§™‡•ç‡§ü> - ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä AI ‡§∏‡§Å‡§ó ‡§ï‡•Å‡§∞‡§æ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
{prefix}gemini [‡§õ‡§µ‡§ø] <‡§™‡•ç‡§∞‡§∂‡•ç‡§®> - ‡§õ‡§µ‡§ø‡§π‡§∞‡•Ç ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
{prefix}gemini [‡§≠‡§ø‡§°‡§ø‡§Ø‡•ã] <‡§™‡•ç‡§∞‡§∂‡•ç‡§®> - ‡§≠‡§ø‡§°‡§ø‡§Ø‡•ã‡§π‡§∞‡•Ç ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
{prefix}gemini [‡§Ö‡§°‡§ø‡§Ø‡•ã] <‡§™‡•ç‡§∞‡§∂‡•ç‡§®> - ‡§Ö‡§°‡§ø‡§Ø‡•ã ‡§ü‡•ç‡§∞‡§æ‡§®‡•ç‡§∏‡§ï‡•ç‡§∞‡§æ‡§á‡§¨/‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
{prefix}gemini generate <‡§µ‡§ø‡§µ‡§∞‡§£> - ‡§õ‡§µ‡§ø‡§π‡§∞‡•Ç ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç
{prefix}gemini clear - ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ñ‡§æ‡§≤‡•Ä ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç`
        },
        slash: true,
        options: [
            {
                name: "prompt",
                description: "Your question or prompt for Gemini AI",
                type: 3,
                required: true
            },
            {
                name: "image",
                description: "Image to analyze (optional)",
                type: 11,
                required: false
            },
            {
                name: "mode",
                description: "AI mode selection",
                type: 3,
                required: false,
                choices: [
                    { name: "Chat (Fast)", value: "flash" },
                    { name: "Advanced Reasoning (Pro)", value: "pro" },
                    { name: "Image Generation", value: "image" },
                    { name: "Clear History", value: "clear" }
                ]
            }
        ]
    },

    langs: {
        en: {
            noPrompt: "‚ùå Please provide a prompt!\nExample: `{prefix}gemini What is quantum computing?`",
            thinking: "üß† Gemini is thinking...",
            analyzing: "üîç Analyzing your {type}...",
            generating: "üé® Generating image...",
            historyCleared: "‚úÖ Conversation history cleared!",
            error: "‚ùå Error: {error}",
            tooLarge: "‚ùå File too large! Maximum size: {size}MB",
            unsupportedFormat: "‚ùå Unsupported file format: {format}",
            downloadError: "‚ùå Failed to download attachment",
            responseTitle: "üíé Gemini AI Response",
            imageGenerated: "üé® Image Generated",
            conversationInfo: "üí¨ Conversation: {count}/{max} messages",
            features: "üåü Available Features",
            selectFeature: "Choose a feature below:",
            multiModalAnalysis: "Multi-Modal Analysis Complete",
            audioTranscribed: "Audio Transcription Complete",
            videoAnalyzed: "Video Analysis Complete"
        },
        ne: {
            noPrompt: "‚ùå ‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§Æ‡•ç‡§™‡•ç‡§ü ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ó‡§∞‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç!\n‡§â‡§¶‡§æ‡§π‡§∞‡§£: `{prefix}gemini ‡§ï‡•ç‡§µ‡§æ‡§®‡•ç‡§ü‡§Æ ‡§ï‡§Æ‡•ç‡§™‡•ç‡§Ø‡•Å‡§ü‡§ø‡§ô ‡§ï‡•á ‡§π‡•ã?`",
            thinking: "üß† ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä ‡§∏‡•ã‡§ö‡•ç‡§¶‡•à‡§õ...",
            analyzing: "üîç ‡§§‡§™‡§æ‡§à‡§Ç‡§ï‡•ã {type} ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ó‡§∞‡•ç‡§¶‡•à...",
            generating: "üé® ‡§õ‡§µ‡§ø ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ó‡§∞‡•ç‡§¶‡•à...",
            historyCleared: "‚úÖ ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§ñ‡§æ‡§≤‡•Ä ‡§ó‡§∞‡§ø‡§Ø‡•ã!",
            error: "‚ùå ‡§§‡•ç‡§∞‡•Å‡§ü‡§ø: {error}",
            tooLarge: "‚ùå ‡§´‡§æ‡§á‡§≤ ‡§ß‡•á‡§∞‡•à ‡§†‡•Ç‡§≤‡•ã ‡§õ! ‡§Ö‡§ß‡§ø‡§ï‡§§‡§Æ ‡§Ü‡§ï‡§æ‡§∞: {size}MB",
            unsupportedFormat: "‚ùå ‡§Ö‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§´‡§æ‡§á‡§≤ ‡§¢‡§æ‡§Å‡§ö‡§æ: {format}",
            downloadError: "‚ùå ‡§∏‡§Ç‡§≤‡§ó‡•ç‡§®‡§ï ‡§°‡§æ‡§â‡§®‡§≤‡•ã‡§° ‡§ó‡§∞‡•ç‡§® ‡§Ö‡§∏‡§´‡§≤",
            responseTitle: "üíé ‡§ú‡•á‡§Æ‡§ø‡§®‡•Ä AI ‡§™‡•ç‡§∞‡§§‡§ø‡§ï‡•ç‡§∞‡§ø‡§Ø‡§æ",
            imageGenerated: "üé® ‡§õ‡§µ‡§ø ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ó‡§∞‡§ø‡§Ø‡•ã",
            conversationInfo: "üí¨ ‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™: {count}/{max} ‡§∏‡§®‡•ç‡§¶‡•á‡§∂‡§π‡§∞‡•Ç",
            features: "üåü ‡§â‡§™‡§≤‡§¨‡•ç‡§ß ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§π‡§∞‡•Ç",
            selectFeature: "‡§§‡§≤ ‡§è‡§ï ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ ‡§õ‡§æ‡§®‡•ç‡§®‡•Å‡§π‡•ã‡§∏‡•ç:",
            multiModalAnalysis: "‡§Æ‡§≤‡•ç‡§ü‡•Ä-‡§Æ‡•ã‡§°‡§≤ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§™‡•Ç‡§∞‡•ç‡§£",
            audioTranscribed: "‡§Ö‡§°‡§ø‡§Ø‡•ã ‡§ü‡•ç‡§∞‡§æ‡§®‡•ç‡§∏‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§™‡•Ç‡§∞‡•ç‡§£",
            videoAnalyzed: "‡§≠‡§ø‡§°‡§ø‡§Ø‡•ã ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§™‡•Ç‡§∞‡•ç‡§£"
        }
    },

    onStart: async ({ message, interaction, args, getLang, prefix, event }) => {
        const isSlash = !!interaction;
        const userId = isSlash ? interaction.user.id : message.author.id;
        const userTag = isSlash ? interaction.user.tag : message.author.tag;

        let prompt = '';
        let selectedMode = 'flash';
        let attachmentUrl = null;
        let attachmentType = null;

        if (isSlash) {
            prompt = interaction.options?.getString('prompt') || '';
            selectedMode = interaction.options?.getString('mode') || 'flash';
            const imageAttachment = interaction.options?.getAttachment('image');
            if (imageAttachment) {
                attachmentUrl = imageAttachment.url;
                attachmentType = imageAttachment.contentType;
            }
        } else {
            prompt = args.join(' ');
            
            if (message.attachments && message.attachments.size > 0) {
                const attachment = message.attachments.first();
                attachmentUrl = attachment.url;
                attachmentType = attachment.contentType;
            }

            if (message.reference) {
                try {
                    const repliedMsg = await message.channel.messages.fetch(message.reference.messageId);
                    if (repliedMsg.attachments && repliedMsg.attachments.size > 0) {
                        const attachment = repliedMsg.attachments.first();
                        attachmentUrl = attachment.url;
                        attachmentType = attachment.contentType;
                    }
                } catch (e) {}
            }
        }

        if (prompt.toLowerCase().startsWith('generate ')) {
            selectedMode = 'image';
            prompt = prompt.substring(9).trim();
        } else if (prompt.toLowerCase() === 'clear') {
            selectedMode = 'clear';
        }

        if (selectedMode === 'clear') {
            conversationHistory.delete(userId);
            return isSlash 
                ? interaction.reply(getLang("historyCleared"))
                : message.reply(getLang("historyCleared"));
        }

        if (!prompt || prompt.trim().length === 0) {
            const response = getLang("noPrompt").replace('{prefix}', prefix);
            return isSlash ? interaction.reply(response) : message.reply(response);
        }

        if (isSlash && !interaction.deferred) {
            await interaction.deferReply();
        }

        const thinkingMsg = selectedMode === 'image' 
            ? getLang("generating")
            : attachmentUrl 
                ? getLang("analyzing").replace('{type}', getFileType(attachmentType))
                : getLang("thinking");

        const initialMsg = isSlash 
            ? await interaction.editReply(thinkingMsg)
            : await message.reply(thinkingMsg);

        try {
            let response;

            if (selectedMode === 'image') {
                response = await generateImage(prompt);
                
                if (response.imagePath) {
                    const attachment = new AttachmentBuilder(response.imagePath, { name: 'generated-image.png' });
                    const embed = new EmbedBuilder()
                        .setTitle(getLang("imageGenerated"))
                        .setDescription(`**Prompt:** ${prompt}`)
                        .setImage('attachment://generated-image.png')
                        .setColor(0x4285f4)
                        .setFooter({ text: `Generated by ${userTag}` })
                        .setTimestamp();

                    const buttons = createActionButtons(userId);
                    
                    const replyMsg = isSlash
                        ? await interaction.editReply({ embeds: [embed], files: [attachment], components: [buttons] })
                        : await initialMsg.edit({ embeds: [embed], files: [attachment], components: [buttons] });

                    setTimeout(() => {
                        if (fs.existsSync(response.imagePath)) {
                            fs.unlinkSync(response.imagePath);
                        }
                    }, 30000);

                    setupButtonCollector(replyMsg, userId, prompt, getLang, userTag, 'image');
                    return;
                }
            } else if (attachmentUrl) {
                response = await analyzeMultiModal(prompt, attachmentUrl, attachmentType, selectedMode);
            } else {
                response = await chatWithGemini(userId, prompt, selectedMode);
            }

            const history = conversationHistory.get(userId) || [];
            const embed = new EmbedBuilder()
                .setTitle(getLang("responseTitle"))
                .setDescription(truncateText(response.text, 4000))
                .setColor(0x4285f4)
                .setFooter({ 
                    text: `${userTag} ‚Ä¢ ${getLang("conversationInfo").replace('{count}', history.length).replace('{max}', MAX_HISTORY)}` 
                })
                .setTimestamp();

            if (response.imageUrl) {
                embed.setImage(response.imageUrl);
            }

            const buttons = createActionButtons(userId);
            const selectMenu = createFeatureMenu();

            const replyMsg = isSlash
                ? await interaction.editReply({ embeds: [embed], components: [buttons, selectMenu] })
                : await initialMsg.edit({ embeds: [embed], components: [buttons, selectMenu] });

            setupButtonCollector(replyMsg, userId, prompt, getLang, userTag);
            setupSelectMenuCollector(replyMsg, userId, getLang, userTag);

        } catch (error) {
            console.error('Gemini error:', error);
            const errorMsg = getLang("error").replace('{error}', error.message);
            return isSlash 
                ? interaction.editReply(errorMsg)
                : initialMsg.edit(errorMsg);
        }
    },

    onReply: async ({ message, event, Reply, getLang, prefix }) => {
        const userId = message.author.id;
        const userTag = message.author.tag;
        const prompt = event.body;

        if (!prompt || prompt.trim().length === 0) return;

        const thinkingMsg = await Reply(getLang("thinking"));

        try {
            let attachmentUrl = null;
            let attachmentType = null;

            if (message.attachments && message.attachments.size > 0) {
                const attachment = message.attachments.first();
                attachmentUrl = attachment.url;
                attachmentType = attachment.contentType;
            }

            let response;
            if (attachmentUrl) {
                response = await analyzeMultiModal(prompt, attachmentUrl, attachmentType, 'flash');
            } else {
                response = await chatWithGemini(userId, prompt, 'flash');
            }

            const history = conversationHistory.get(userId) || [];
            const embed = new EmbedBuilder()
                .setTitle(getLang("responseTitle"))
                .setDescription(truncateText(response.text, 4000))
                .setColor(0x4285f4)
                .setFooter({ 
                    text: `${userTag} ‚Ä¢ ${getLang("conversationInfo").replace('{count}', history.length).replace('{max}', MAX_HISTORY)}` 
                })
                .setTimestamp();

            const buttons = createActionButtons(userId);
            const selectMenu = createFeatureMenu();

            const replyMsg = await thinkingMsg.edit({ embeds: [embed], components: [buttons, selectMenu] });
            
            setupButtonCollector(replyMsg, userId, prompt, getLang, userTag);
            setupSelectMenuCollector(replyMsg, userId, getLang, userTag);

        } catch (error) {
            console.error('Gemini onReply error:', error);
            await thinkingMsg.edit(getLang("error").replace('{error}', error.message));
        }
    }
};

async function chatWithGemini(userId, prompt, mode = 'flash') {
    const modelName = mode === 'pro' ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
    
    if (!conversationHistory.has(userId)) {
        conversationHistory.set(userId, []);
    }

    const history = conversationHistory.get(userId);
    
    const contents = [];
    for (const msg of history) {
        contents.push({ role: 'user', parts: [{ text: msg.user }] });
        contents.push({ role: 'model', parts: [{ text: msg.model }] });
    }
    contents.push({ role: 'user', parts: [{ text: prompt }] });

    const response = await ai.models.generateContent({
        model: modelName,
        contents: contents
    });

    const responseText = response.text || "I couldn't generate a response.";
    
    history.push({ user: prompt, model: responseText });
    
    if (history.length > MAX_HISTORY) {
        history.shift();
    }

    return { text: responseText };
}

async function analyzeMultiModal(prompt, fileUrl, fileType, mode = 'flash') {
    const modelName = mode === 'pro' ? 'gemini-2.5-pro' : 'gemini-2.5-flash';
    const maxSize = 20 * 1024 * 1024;
    
    try {
        const response = await axios.get(fileUrl, { 
            responseType: 'arraybuffer', 
            maxContentLength: maxSize,
            maxBodyLength: maxSize
        });
        const buffer = Buffer.from(response.data);
        
        if (buffer.length > maxSize) {
            throw new Error(`File too large! Maximum size is 20MB, your file is ${(buffer.length / 1024 / 1024).toFixed(2)}MB`);
        }
        
        const base64Data = buffer.toString('base64');

    let mimeType = fileType || 'application/octet-stream';
    
    if (fileUrl.includes('.mp4') || fileUrl.includes('.mov') || fileUrl.includes('.avi')) mimeType = 'video/mp4';
    else if (fileUrl.includes('.mp3')) mimeType = 'audio/mp3';
    else if (fileUrl.includes('.wav')) mimeType = 'audio/wav';
    else if (fileUrl.includes('.ogg')) mimeType = 'audio/ogg';
    else if (fileUrl.includes('.jpg') || fileUrl.includes('.jpeg')) mimeType = 'image/jpeg';
    else if (fileUrl.includes('.png')) mimeType = 'image/png';
    else if (fileUrl.includes('.gif')) mimeType = 'image/gif';
    else if (fileUrl.includes('.webp')) mimeType = 'image/webp';
    else if (fileUrl.includes('.pdf')) mimeType = 'application/pdf';

    const contents = [
        {
            role: 'user',
            parts: [
                {
                    inlineData: {
                        data: base64Data,
                        mimeType: mimeType
                    }
                },
                { text: prompt || "Analyze this file in detail and provide a comprehensive description." }
            ]
        }
    ];

        const result = await ai.models.generateContent({
            model: modelName,
            contents: contents
        });

        return { text: result.text || "Analysis complete." };
    } catch (error) {
        if (error.code === 'ERR_BAD_RESPONSE' || error.message.includes('maxContentLength')) {
            throw new Error('File too large! Maximum size is 20MB');
        }
        throw error;
    }
}

async function generateImage(prompt) {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.0-flash-preview-image-generation',
            contents: [{ role: 'user', parts: [{ text: prompt }] }],
            config: {
                responseModalities: [Modality.TEXT, Modality.IMAGE]
            }
        });

        const candidates = response.candidates;
        if (!candidates || candidates.length === 0) {
            throw new Error('No image generated');
        }

        const content = candidates[0].content;
        if (!content || !content.parts) {
            throw new Error('No content in response');
        }

        for (const part of content.parts) {
            if (part.inlineData && part.inlineData.data) {
                const tmpDir = path.join(__dirname, 'tmp');
                fs.ensureDirSync(tmpDir);
                const filename = `gemini_gen_${Date.now()}.png`;
                const filepath = path.join(tmpDir, filename);
                
                const imageData = Buffer.from(part.inlineData.data, 'base64');
                fs.writeFileSync(filepath, imageData);
                
                return { imagePath: filepath, text: part.text || '' };
            }
        }

        throw new Error('No image data found in response');
    } catch (error) {
        throw new Error(`Image generation failed: ${error.message}`);
    }
}

function createActionButtons(userId) {
    return new ActionRowBuilder()
        .addComponents(
            new ButtonBuilder()
                .setCustomId(`gemini_continue_${userId}_${Date.now()}`)
                .setLabel('Continue Chat')
                .setEmoji('üí¨')
                .setStyle(ButtonStyle.Primary),
            new ButtonBuilder()
                .setCustomId(`gemini_clear_${userId}_${Date.now()}`)
                .setLabel('Clear History')
                .setEmoji('üóëÔ∏è')
                .setStyle(ButtonStyle.Danger),
            new ButtonBuilder()
                .setCustomId(`gemini_export_${userId}_${Date.now()}`)
                .setLabel('Export Chat')
                .setEmoji('üì•')
                .setStyle(ButtonStyle.Secondary)
        );
}

function createFeatureMenu() {
    return new ActionRowBuilder()
        .addComponents(
            new StringSelectMenuBuilder()
                .setCustomId('gemini_feature_select')
                .setPlaceholder('üåü Choose a feature...')
                .addOptions([
                    {
                        label: 'Text Generation',
                        description: 'Generate creative text, stories, code',
                        value: 'text',
                        emoji: 'üìù'
                    },
                    {
                        label: 'Image Analysis',
                        description: 'Analyze and describe images',
                        value: 'image_analyze',
                        emoji: 'üñºÔ∏è'
                    },
                    {
                        label: 'Image Generation',
                        description: 'Create AI-generated images',
                        value: 'image_gen',
                        emoji: 'üé®'
                    },
                    {
                        label: 'Video Analysis',
                        description: 'Analyze video content and extract info',
                        value: 'video',
                        emoji: 'üé•'
                    },
                    {
                        label: 'Audio Transcription',
                        description: 'Transcribe and analyze audio',
                        value: 'audio',
                        emoji: 'üéµ'
                    },
                    {
                        label: 'Code Assistant',
                        description: 'Write, debug, and explain code',
                        value: 'code',
                        emoji: 'üíª'
                    },
                    {
                        label: 'Advanced Reasoning',
                        description: 'Use Gemini Pro for complex tasks',
                        value: 'pro',
                        emoji: 'üß†'
                    }
                ])
        );
}

function setupButtonCollector(message, userId, prompt, getLang, userTag, context = 'chat') {
    const collector = message.createMessageComponentCollector({
        filter: (i) => i.customId.includes('gemini_') && i.customId.includes(userId),
        time: 300000
    });

    collector.on('collect', async (interaction) => {
        const customId = interaction.customId;

        try {
            if (customId.includes('gemini_continue_')) {
                await interaction.reply({
                    content: 'üí¨ Type your next message to continue the conversation!',
                    ephemeral: false
                });
            } else if (customId.includes('gemini_clear_')) {
                conversationHistory.delete(userId);
                await interaction.reply({
                    content: '‚úÖ Conversation history cleared!',
                    ephemeral: false
                });
            } else if (customId.includes('gemini_export_')) {
                const history = conversationHistory.get(userId) || [];
                
                if (history.length === 0) {
                    return interaction.reply({
                        content: '‚ùå No conversation history to export!',
                        ephemeral: true
                    });
                }

                let exportText = `Gemini AI Conversation Export\nUser: ${userTag}\nDate: ${new Date().toLocaleString()}\n${'='.repeat(50)}\n\n`;
                
                history.forEach((msg, index) => {
                    exportText += `[${index + 1}] User: ${msg.user}\n\n`;
                    exportText += `[${index + 1}] Gemini: ${msg.model}\n\n`;
                    exportText += '-'.repeat(50) + '\n\n';
                });

                const tmpDir = path.join(__dirname, 'tmp');
                fs.ensureDirSync(tmpDir);
                const filename = `gemini_chat_${userId}_${Date.now()}.txt`;
                const filepath = path.join(tmpDir, filename);
                
                fs.writeFileSync(filepath, exportText);
                
                const attachment = new AttachmentBuilder(filepath, { name: 'conversation.txt' });
                
                await interaction.reply({
                    content: 'üì• Here\'s your conversation export!',
                    files: [attachment],
                    ephemeral: false
                });

                setTimeout(() => {
                    if (fs.existsSync(filepath)) {
                        fs.unlinkSync(filepath);
                    }
                }, 10000);
            }
        } catch (error) {
            console.error('Button interaction error:', error);
            if (!interaction.replied && !interaction.deferred) {
                await interaction.reply({
                    content: `‚ùå Error: ${error.message}`,
                    ephemeral: true
                });
            }
        }
    });
}

function setupSelectMenuCollector(message, userId, getLang, userTag) {
    const collector = message.createMessageComponentCollector({
        filter: (i) => i.customId === 'gemini_feature_select',
        time: 300000
    });

    collector.on('collect', async (interaction) => {
        const selectedFeature = interaction.values[0];

        const featureInfo = {
            text: {
                title: 'üìù Text Generation',
                description: 'I can help you with:\n‚Ä¢ Creative writing & stories\n‚Ä¢ Essays & articles\n‚Ä¢ Translations\n‚Ä¢ Summaries\n‚Ä¢ Q&A\n\nJust ask me anything!',
                example: 'Example: "Write a short story about a robot learning to paint"'
            },
            image_analyze: {
                title: 'üñºÔ∏è Image Analysis',
                description: 'Upload an image and I can:\n‚Ä¢ Describe what\'s in it\n‚Ä¢ Answer questions about it\n‚Ä¢ Extract text (OCR)\n‚Ä¢ Identify objects & scenes\n‚Ä¢ Provide detailed analysis',
                example: 'Example: Upload an image and ask "What\'s in this picture?"'
            },
            image_gen: {
                title: 'üé® Image Generation',
                description: 'I can create images for you!\n\nUse: `gemini generate <description>`',
                example: 'Example: "gemini generate a cyberpunk city at sunset"'
            },
            video: {
                title: 'üé• Video Analysis',
                description: 'Upload a video and I can:\n‚Ä¢ Summarize content\n‚Ä¢ Extract key moments\n‚Ä¢ Answer questions\n‚Ä¢ Transcribe audio\n‚Ä¢ Analyze scenes',
                example: 'Example: Upload a video and ask "Summarize this video"'
            },
            audio: {
                title: 'üéµ Audio Transcription',
                description: 'Upload audio and I can:\n‚Ä¢ Transcribe speech to text\n‚Ä¢ Identify speakers\n‚Ä¢ Summarize content\n‚Ä¢ Answer questions about it',
                example: 'Example: Upload audio and ask "Transcribe this"'
            },
            code: {
                title: 'üíª Code Assistant',
                description: 'I can help with coding:\n‚Ä¢ Write code in any language\n‚Ä¢ Debug errors\n‚Ä¢ Explain code\n‚Ä¢ Optimize algorithms\n‚Ä¢ Code reviews',
                example: 'Example: "Write a Python function to sort a list"'
            },
            pro: {
                title: 'üß† Advanced Reasoning (Pro)',
                description: 'Using Gemini 2.5 Pro for:\n‚Ä¢ Complex analysis\n‚Ä¢ Mathematical problems\n‚Ä¢ Scientific reasoning\n‚Ä¢ Detailed research\n‚Ä¢ Advanced tasks',
                example: 'Add "mode: pro" or use slash command with Pro mode'
            }
        };

        const info = featureInfo[selectedFeature];
        
        const embed = new EmbedBuilder()
            .setTitle(info.title)
            .setDescription(info.description)
            .addFields({ name: 'üí° How to Use', value: info.example })
            .setColor(0x4285f4)
            .setFooter({ text: `Requested by ${userTag}` })
            .setTimestamp();

        await interaction.reply({
            embeds: [embed],
            ephemeral: false
        });
    });
}

function getFileType(mimeType) {
    if (!mimeType) return 'file';
    if (mimeType.startsWith('image/')) return 'image';
    if (mimeType.startsWith('video/')) return 'video';
    if (mimeType.startsWith('audio/')) return 'audio';
    if (mimeType.includes('pdf')) return 'PDF';
    return 'file';
}

function truncateText(text, maxLength) {
    if (text.length <= maxLength) return text;
    return text.substring(0, maxLength - 3) + '...';
}
